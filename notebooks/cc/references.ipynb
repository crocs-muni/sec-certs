{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "This notebook contains analysis of certificate references in Common Criteria certificates.\n",
    "\n",
    "The notebook has two parts, an analysis part and a network visualization part.\n",
    "But first some common initialization and data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from sec_certs.dataset.common_criteria import CCDataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pysankey import sankey\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "sns.set_theme(style='white')\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.5\n",
    "plt.rcParams[\"legend.fontsize\"] = 6.5\n",
    "plt.rcParams[\"xtick.labelsize\"] = 8\n",
    "plt.rcParams[\"ytick.labelsize\"] = 8\n",
    "plt.rcParams[\"ytick.left\"] = True\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams['ytick.major.width'] = 0.5\n",
    "plt.rcParams['ytick.major.pad'] = 0\n",
    "plt.rcParams[\"xtick.bottom\"] = True\n",
    "plt.rcParams['xtick.major.size'] = 5\n",
    "plt.rcParams['xtick.major.width'] = 0.5\n",
    "plt.rcParams['xtick.major.pad'] = 0\n",
    "plt.rcParams[\"pgf.texsystem\"] = \"pdflatex\"\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"pgf.rcfonts\"] = False\n",
    "plt.rcParams[\"axes.titlesize\"] = 8\n",
    "plt.rcParams[\"legend.handletextpad\"] = 0.3\n",
    "plt.rcParams['lines.markersize'] = 4\n",
    "plt.rcParams['savefig.pad_inches'] = 0.01\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "#plt.style.use(\"seaborn-whitegrid\")\n",
    "#sns.set_palette(\"deep\")\n",
    "#sns.set_context(\"notebook\")  # Set to \"paper\" for use in paper :)\n",
    "\n",
    "#plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading CC Dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 135M/135M [00:26<00:00, 5.34MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "dset = CCDataset.from_web_latest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dset.to_pandas()\n",
    "df_id_rich = df.loc[df.cert_id.notnull()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reference analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count numbers of reference-rich certificates\n",
    "\n",
    "- From the numbers follows that whenever a certificate is directly referencing some else, it also indirectly references some else\n",
    "- We have more outgoing references than ingoing references, which kinda makes sense. You don't have to be aware that some other cert references you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\newcommand{\\numCcAllDirectReferencing}{1500}\n",
      "\\newcommand{\\numCcAllNotDirectReferencing}{3641}\n",
      "\\newcommand{\\numCcWithIdDirectReferencing}{1500}\n",
      "\\newcommand{\\numCcWithIdNotDirectReferencing}{3565}\n"
     ]
    }
   ],
   "source": [
    "df[\"has_outgoing_direct_references\"] = df.directly_referencing.notnull()\n",
    "df[\"has_incoming_direct_references\"] = df.directly_referenced_by.notnull()\n",
    "df[\"has_outgoing_indirect_references\"] = df.indirectly_referencing.notnull()\n",
    "df[\"has_incoming_indirect_references\"] = df.indirectly_referenced_by.notnull()\n",
    "\n",
    "#df.loc[:, [\"directly_referenced_by\", \"indirectly_referenced_by\", \"directly_referencing\", \"indirectly_referencing\"]].notnull().describe()\n",
    "\n",
    "print(f\"\\\\newcommand{{\\\\numCcAllDirectReferencing}}{{{df.has_outgoing_direct_references.sum()}}}\")\n",
    "print(f\"\\\\newcommand{{\\\\numCcAllNotDirectReferencing}}{{{len(df) - df.has_outgoing_direct_references.sum()}}}\")\n",
    "\n",
    "df_id_rich[\"has_outgoing_direct_references\"] = df_id_rich.directly_referencing.notnull()\n",
    "df_id_rich[\"has_incoming_direct_references\"] = df_id_rich.directly_referenced_by.notnull()\n",
    "df_id_rich[\"has_outgoing_indirect_references\"] = df_id_rich.indirectly_referencing.notnull()\n",
    "df_id_rich[\"has_incoming_indirect_references\"] = df_id_rich.indirectly_referenced_by.notnull()\n",
    "\n",
    "print(f\"\\\\newcommand{{\\\\numCcWithIdDirectReferencing}}{{{df_id_rich.has_outgoing_direct_references.sum()}}}\")\n",
    "print(f\"\\\\newcommand{{\\\\numCcWithIdNotDirectReferencing}}{{{len(df_id_rich) - df_id_rich.has_outgoing_direct_references.sum()}}}\")\n",
    "\n",
    "#df_id_rich.loc[:, [\"directly_referenced_by\", \"indirectly_referenced_by\", \"directly_referencing\", \"indirectly_referencing\"]].notnull().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\newcommand{\\numCCActiveDirectReferencing}{545}\n",
      "\\newcommand{\\numCCActiveDirectReferencingArchived}{169}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\\\newcommand{{\\\\numCCActiveDirectReferencing}}{{{df_id_rich.loc[df_id_rich.status == 'active'].has_outgoing_direct_references.sum()}}}\")\n",
    "\n",
    "archived_cert_id_list = set(df_id_rich[df_id_rich.status == \"archived\"].cert_id)\n",
    "def contains_archived_cert_reference(referencing):\n",
    "    if referencing is np.nan:\n",
    "        return False\n",
    "    \n",
    "    return bool(archived_cert_id_list.intersection(referencing))\n",
    "print(f\"\\\\newcommand{{\\\\numCCActiveDirectReferencingArchived}}{{{df_id_rich[df_id_rich.status == 'active'].directly_referencing.apply(contains_archived_cert_reference).sum()}}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot direct references per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 2)\n",
    "figure.set_size_inches(16, 10)\n",
    "figure.set_tight_layout(True)\n",
    "\n",
    "col_to_depict = [\"has_outgoing_direct_references\", \"has_incoming_direct_references\"]\n",
    "\n",
    "for index, col in enumerate(col_to_depict):\n",
    "    countplot = sns.countplot(data=df, x=\"category\", hue=col, ax=axes[index])\n",
    "    countplot.set(\n",
    "        xlabel=\"Category\",\n",
    "        ylabel=\"Outgoing direct references\",\n",
    "        title=f\"Countplot of {' '.join(col.split('_'))}\",\n",
    "    )\n",
    "    countplot.tick_params(axis=\"x\", rotation=90)\n",
    "    countplot.legend(title=' '.join(col.split('_')), bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\newcommand{\\numCCDirectRefsSameCategory}{2133}\n",
      "\\newcommand{\\numCCDirectRefsOtherCategory}{192}\n",
      "\\newcommand{\\numCCDirectRefs}{2325}\n",
      "\\newcommand{\\numCCDirectRefsFromSmartcards}{1896}\n"
     ]
    }
   ],
   "source": [
    "cert_id_to_category_mapping = dict(zip(df.cert_id, df.category))\n",
    "cert_id_to_category_mapping[np.NaN] = \"No references\"\n",
    "\n",
    "exploded = df_id_rich.loc[:, [\"category\", \"directly_referencing\"]].explode(\"directly_referencing\")\n",
    "\n",
    "exploded[\"ref_category\"] = exploded.directly_referencing.map(cert_id_to_category_mapping)\n",
    "exploded = exploded.loc[exploded.ref_category.notnull()]\n",
    "\n",
    "exploded_with_refs = exploded.loc[exploded.ref_category != \"No references\"]\n",
    "print(f\"\\\\newcommand{{\\\\numCCDirectRefsSameCategory}}{{{(exploded_with_refs.category == exploded_with_refs.ref_category).sum()}}}\")\n",
    "print(f\"\\\\newcommand{{\\\\numCCDirectRefsOtherCategory}}{{{(exploded_with_refs.category != exploded_with_refs.ref_category).sum()}}}\")\n",
    "print(f\"\\\\newcommand{{\\\\numCCDirectRefs}}{{{len(exploded_with_refs)}}}\")\n",
    "print(f\"\\\\newcommand{{\\\\numCCDirectRefsFromSmartcards}}{{{(exploded_with_refs.category == 'ICs, Smart Cards and Smart Card-Related Devices and Systems').sum()}}}\")\n",
    "\n",
    "all_categories = set(exploded.category.unique()) | set(exploded.ref_category.unique())\n",
    "colors = list(sns.color_palette(\"hls\", len(all_categories), as_cmap=False).as_hex())\n",
    "color_dict = dict(zip(all_categories, colors))\n",
    "\n",
    "figure, axes = plt.subplots(1, 1)\n",
    "figure.set_size_inches(24, 10)\n",
    "figure.set_tight_layout(True)\n",
    "\n",
    "sankey(exploded.category, exploded.ref_category, colorDict=color_dict, leftLabels=list(exploded.category.unique()), rightLabels=list(exploded.ref_category.unique()), fontsize=12, ax=axes)\n",
    "\n",
    "figure.savefig(\"category_references.pdf\", bbox_inches=\"tight\")\n",
    "figure.savefig(\"category_references.pgf\", bbox_inches=\"tight\")\n",
    "plt.close(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot direct references per scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 2)\n",
    "figure.set_size_inches(14, 4)\n",
    "figure.set_tight_layout(True)\n",
    "\n",
    "col_to_depict = [\"has_outgoing_direct_references\", \"has_incoming_direct_references\"]\n",
    "\n",
    "for index, col in enumerate(col_to_depict):\n",
    "    countplot = sns.countplot(data=df, x=\"scheme\", hue=col, ax=axes[index])\n",
    "    countplot.set(\n",
    "        xlabel=\"Category\",\n",
    "        ylabel=\"Outgoing direct references\",\n",
    "        title=f\"Countplot of {' '.join(col.split('_'))}\",\n",
    "    )\n",
    "    countplot.tick_params(axis=\"x\", rotation=90)\n",
    "    countplot.legend(title=' '.join(col.split('_')), bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of certificates referencing archived certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of certificates that reference some archived certificate: 933\n"
     ]
    }
   ],
   "source": [
    "def references_archived_cert(references):\n",
    "    if pd.isnull(references):\n",
    "        return False\n",
    "\n",
    "    return any([x in cert_ids] for x in references)\n",
    "\n",
    "cert_ids = set(df.loc[((df.cert_id.notnull()) & (df.status == \"archived\")), \"cert_id\"].tolist())\n",
    "df[\"references_archived_cert\"] = df.directly_referenced_by.map(references_archived_cert)\n",
    "\n",
    "print(f\"Number of certificates that reference some archived certificate: {df.loc[df.references_archived_cert].shape[0]}\")\n",
    "\n",
    "col_to_depict = [\"category\", \"scheme\"]\n",
    "\n",
    "figure, axes = plt.subplots(1, 2)\n",
    "figure.set_size_inches(14, 8)\n",
    "figure.set_tight_layout(True)\n",
    "\n",
    "for index, col in enumerate(col_to_depict):\n",
    "    countplot = sns.countplot(data=df, x=col, hue=\"references_archived_cert\", ax=axes[index])\n",
    "    countplot.set(\n",
    "        xlabel=col,\n",
    "        ylabel=\"Outgoing direct references\",\n",
    "        title=\"Countplot of certificates that reference some archived certificate\",\n",
    "    )\n",
    "    countplot.tick_params(axis=\"x\", rotation=90)\n",
    "    countplot.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count scheme references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cert_id_to_scheme_mapping = dict(zip(df.cert_id, df.scheme))\n",
    "\n",
    "df_ref_rich = df_id_rich.loc[df.directly_referencing.notnull()]\n",
    "exploded = df_ref_rich.loc[:, [\"scheme\", \"directly_referencing\"]].explode(\"directly_referencing\")\n",
    "\n",
    "exploded[\"ref_scheme\"] = exploded.directly_referencing.map(cert_id_to_scheme_mapping)\n",
    "exploded = exploded.loc[exploded.ref_scheme.notnull()]\n",
    "\n",
    "all_schemes = set(exploded.scheme.unique()) | set(exploded.ref_scheme.unique())\n",
    "colors = list(sns.color_palette(\"hls\", len(all_schemes), as_cmap=False).as_hex())\n",
    "color_dict = dict(zip(all_schemes, colors))\n",
    "\n",
    "figure, axes = plt.subplots(1, 1)\n",
    "figure.set_size_inches(4, 4)\n",
    "figure.set_tight_layout(True)\n",
    "\n",
    "sankey(exploded.scheme, exploded.ref_scheme, colorDict=color_dict, leftLabels=list(exploded.scheme.unique()), rightLabels=list(exploded.ref_scheme.unique()), fontsize=7, ax=axes)\n",
    "\n",
    "figure.savefig(\"scheme_references.pdf\", bbox_inches=\"tight\")\n",
    "figure.savefig(\"scheme_references.pgf\", bbox_inches=\"tight\")\n",
    "plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\newcommand{\\numCCUSReferencing}{4}\n",
      "\\newcommand{\\numCCUS}{959}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\\\newcommand{{\\\\numCCUSReferencing}}{{{len(df_id_rich.loc[(df_id_rich.scheme == 'US') & (df_id_rich.directly_referencing.notnull())])}}}\")\n",
    "print(f\"\\\\newcommand{{\\\\numCCUS}}{{{len(df_id_rich.loc[(df_id_rich.scheme == 'US')])}}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal evolution of references\n",
    "\n",
    "Shows plot with relative number of certificates for a given year that reference some other certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_temporal = df.loc[df.year_from < 2022].groupby([\"year_from\"])[\"directly_referencing\"].count().reset_index().set_index(\"year_from\")\n",
    "n_issued_certs = df.groupby(\"year_from\").name.count().reset_index().rename(columns={\"name\": \"n_certs\"}).set_index(\"year_from\")\n",
    "df_temporal.directly_referencing = 100 * df_temporal.directly_referencing / n_issued_certs.n_certs\n",
    "\n",
    "line = sns.lineplot(data=df_temporal, x=\"year_from\", y=\"directly_referencing\")\n",
    "line.yaxis.set_major_formatter(mtick.PercentFormatter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting w.r.t. scheme and category (both are interesting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference network visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "certs_with_ids = {cert.heuristics.cert_id: cert for cert in dset if cert.heuristics.cert_id}\n",
    "\n",
    "print(f\"Certificates in dataset: {len(dset)}\")\n",
    "print(f\"Certificates with extracted IDs: {len(certs_with_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Certificate report references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "refs_cr = nx.DiGraph()\n",
    "for cert_id, cert in certs_with_ids.items():\n",
    "    refs_cr.add_node(cert_id, cert=cert)\n",
    "for cert_id, cert in certs_with_ids.items():\n",
    "    if cr_refs := cert.heuristics.report_references.directly_referencing:\n",
    "        for ref_id in cr_refs:\n",
    "            if ref_id in certs_with_ids:\n",
    "                refs_cr.add_edge(cert_id, ref_id, type=(\"cr\",))\n",
    "print(f\"References in certificate reports: {len(refs_cr.edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Security target references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "refs_st = nx.DiGraph()\n",
    "for cert_id, cert in certs_with_ids.items():\n",
    "    refs_st.add_node(cert_id, cert=cert)\n",
    "for cert_id, cert in certs_with_ids.items():\n",
    "    if st_refs := cert.heuristics.st_references.directly_referencing:\n",
    "        for ref_id in st_refs:\n",
    "            if ref_id in certs_with_ids:\n",
    "                refs_st.add_edge(cert_id, ref_id, type=(\"st\",))\n",
    "print(f\"References in security targets: {len(refs_st.edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "refs = nx.DiGraph()\n",
    "for cert_id, cert in certs_with_ids.items():\n",
    "    refs.add_node(cert_id, cert=cert)\n",
    "\n",
    "for cert_id, cert in certs_with_ids.items():\n",
    "    cr_refs = cert.heuristics.report_references.directly_referencing\n",
    "    st_refs = cert.heuristics.st_references.directly_referencing\n",
    "    cr_refs = set(cr_refs) if cr_refs is not None else set()\n",
    "    st_refs = set(st_refs) if st_refs is not None else set()\n",
    "    both = cr_refs.union(st_refs)\n",
    "    for ref in both:\n",
    "        if ref not in certs_with_ids:\n",
    "            continue\n",
    "        if ref in cr_refs and ref not in st_refs:\n",
    "            refs.add_edge(cert_id, ref, type=(\"cr\", ))\n",
    "        elif ref in st_refs and ref not in cr_refs:\n",
    "            refs.add_edge(cert_id, ref, type=(\"st\", ))\n",
    "        else:\n",
    "            refs.add_edge(cert_id, ref, type=(\"cr\", \"st\"))\n",
    "print(f\"Combined references (not double counted): {len(refs.edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Certificate overview\n",
    "Enter the certificate you are interested in below and see its reference graph component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_id = \"ANSSI-CC-2019/02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cert = certs_with_ids.get(cert_id)\n",
    "if cert is None:\n",
    "    print(f\"Certificate with id {cert_id} is not present in the dataset.\")\n",
    "\n",
    "for component in nx.weakly_connected_components(refs):\n",
    "    if cert_id in component:\n",
    "        break\n",
    "\n",
    "view = nx.subgraph_view(refs, lambda node: node in component)\n",
    "print(f\"Certificate with id {cert_id}:\")\n",
    "print(f\" - is in a component with {len(view.nodes)} certificates and {len(view.edges)} references.\")\n",
    "print(f\" - references {list(view[cert_id].keys())}\")\n",
    "print(f\" - is referenced by {list(view.predecessors(cert_id))}\")\n",
    "print(f\" - its page is at https://seccerts.org/cc/{cert.dgst}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(view, pos=nx.planar_layout(view), with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Some graph metrics\n",
    "From <https://dataground.io/2021/09/29/simple-graph-metrics-networkx-for-beginners/> and\n",
    "<https://theslaps.medium.com/centrality-metrics-via-networkx-python-e13e60ba2740>.\n",
    "Also good <https://www.geeksforgeeks.org/network-centrality-measures-in-a-graph-using-networkx-python/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Density = {nx.density(refs)}\")\n",
    "print(f\"Transitivity = {nx.transitivity(refs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Degree centrality <Popularity> (top 20):\")\n",
    "degree_centrality_vals = [(node, val) for node, val in nx.degree_centrality(refs).items()]\n",
    "degree_centrality_vals.sort(key=lambda pair: pair[1], reverse=True)\n",
    "for pair in degree_centrality_vals[:20]:\n",
    "    print(f\"\\t{pair[0]} = {pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Eigenvector centrality <Influence> (top 20):\")\n",
    "eigenvector_centrality_vals = [(node, val) for node, val in nx.eigenvector_centrality(refs).items()]\n",
    "eigenvector_centrality_vals.sort(key=lambda pair: pair[1], reverse=True)\n",
    "for pair in eigenvector_centrality_vals[:20]:\n",
    "    print(f\"\\t{pair[0]} = {pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Closeness centrality <Centralness> (top 20):\")\n",
    "closeness_centrality_vals = [(node, val) for node, val in nx.closeness_centrality(refs).items()]\n",
    "closeness_centrality_vals.sort(key=lambda pair: pair[1], reverse=True)\n",
    "for pair in closeness_centrality_vals[:20]:\n",
    "    print(f\"\\t{pair[0]} = {pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Betweenness centrality <Bridge> (top 20):\")\n",
    "betweenness_centrality_vals = [(node, val) for node, val in nx.betweenness_centrality(refs).items()]\n",
    "betweenness_centrality_vals.sort(key=lambda pair: pair[1], reverse=True)\n",
    "for pair in betweenness_centrality_vals[:20]:\n",
    "    print(f\"\\t{pair[0]} = {pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "component_lengths = list(filter(lambda comp_len: comp_len > 1, map(len, nx.weakly_connected_components(refs))))\n",
    "component_lengths.sort(reverse=True)\n",
    "print(component_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "big_boy = refs.subgraph(max(nx.weakly_connected_components(refs), key=len))\n",
    "communities = list(nx_comm.greedy_modularity_communities(big_boy))\n",
    "print(len(communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for com in communities:\n",
    "    for i in sorted(com):\n",
    "        print(f\"\\t{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from typing import Any, Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import float64, ndarray\n",
    "from pandas.core.frame import DataFrame\n",
    "from pandas.core.series import Series\n",
    "\n",
    "class PySankeyException(Exception):\n",
    "    \"\"\"Generic PySankey Exception.\"\"\"\n",
    "\n",
    "\n",
    "class NullsInFrame(PySankeyException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class LabelMismatch(PySankeyException):\n",
    "    pass\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def check_data_matches_labels(\n",
    "    labels: Union[List[str], Set[str]], data: Series, side: str\n",
    ") -> None:\n",
    "    \"\"\"Check whether data matches labels.\n",
    "    Raise a LabelMismatch Exception if not.\"\"\"\n",
    "    if len(labels) > 0:\n",
    "        if isinstance(data, list):\n",
    "            data = set(data)\n",
    "        if isinstance(data, pd.Series):\n",
    "            data = set(data.unique().tolist())\n",
    "        if isinstance(labels, list):\n",
    "            labels = set(labels)\n",
    "        if labels != data:\n",
    "            msg = \"\\n\"\n",
    "            if len(labels) <= 20:\n",
    "                msg = \"Labels: \" + \",\".join(labels) + \"\\n\"\n",
    "            if len(data) < 20:\n",
    "                msg += \"Data: \" + \",\".join(data)\n",
    "            raise LabelMismatch(f\"{side} labels and data do not match.{msg}\")\n",
    "\n",
    "\n",
    "def sankey(\n",
    "    left: Union[List, ndarray, Series],\n",
    "    right: Union[ndarray, Series],\n",
    "    leftWeight: Optional[ndarray] = None,\n",
    "    rightWeight: Optional[ndarray] = None,\n",
    "    colorDict: Optional[Dict[str, str]] = None,\n",
    "    leftLabels: Optional[List[str]] = None,\n",
    "    rightLabels: Optional[List[str]] = None,\n",
    "    aspect: int = 4,\n",
    "    rightColor: bool = False,\n",
    "    fontsize: int = 14,\n",
    "    figureName: Optional[str] = None,\n",
    "    closePlot: bool = False,\n",
    "    figSize: Optional[Tuple[int, int]] = None,\n",
    "    ax: Optional[Any] = None,\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Make Sankey Diagram showing flow from left-->right\n",
    "    Inputs:\n",
    "        left = NumPy array of object labels on the left of the diagram\n",
    "        right = NumPy array of corresponding labels on the right of the diagram\n",
    "            len(right) == len(left)\n",
    "        leftWeight = NumPy array of weights for each strip starting from the\n",
    "            left of the diagram, if not specified 1 is assigned\n",
    "        rightWeight = NumPy array of weights for each strip starting from the\n",
    "            right of the diagram, if not specified the corresponding leftWeight\n",
    "            is assigned\n",
    "        colorDict = Dictionary of colors to use for each label\n",
    "            {'label':'color'}\n",
    "        leftLabels = order of the left labels in the diagram\n",
    "        rightLabels = order of the right labels in the diagram\n",
    "        aspect = vertical extent of the diagram in units of horizontal extent\n",
    "        rightColor = If true, each strip in the diagram will be be colored\n",
    "                    according to its left label\n",
    "        figSize = tuple setting the width and height of the sankey diagram.\n",
    "            Defaults to current figure size\n",
    "        ax = optional, matplotlib axes to plot on, otherwise uses current axes.\n",
    "    Output:\n",
    "        ax : matplotlib Axes\n",
    "    \"\"\"\n",
    "    ax, leftLabels, leftWeight, rightLabels, rightWeight = init_values(\n",
    "        ax,\n",
    "        closePlot,\n",
    "        figSize,\n",
    "        figureName,\n",
    "        left,\n",
    "        leftLabels,\n",
    "        leftWeight,\n",
    "        rightLabels,\n",
    "        rightWeight,\n",
    "    )\n",
    "    plt.rc(\"text\", usetex=False)\n",
    "    plt.rc(\"font\", family=\"serif\")\n",
    "    data_frame = _create_dataframe(left, leftWeight, right, rightWeight)\n",
    "    # Identify all labels that appear 'left' or 'right'\n",
    "    all_labels = pd.Series(\n",
    "        np.r_[data_frame.left.unique(), data_frame.right.unique()]\n",
    "    ).unique()\n",
    "    LOGGER.debug(\"Labels to handle : %s\", all_labels)\n",
    "    leftLabels, rightLabels = identify_labels(data_frame, leftLabels, rightLabels)\n",
    "    colorDict = create_colors(all_labels, colorDict)  # type: ignore\n",
    "    ns_l, ns_r = determine_widths(data_frame, leftLabels, rightLabels)\n",
    "    # Determine positions of left label patches and total widths\n",
    "    leftWidths, topEdge = _get_positions_and_total_widths(\n",
    "        data_frame, leftLabels, \"left\"\n",
    "    )\n",
    "    # Determine positions of right label patches and total widths\n",
    "    rightWidths, topEdge = _get_positions_and_total_widths(\n",
    "        data_frame, rightLabels, \"right\"\n",
    "    )\n",
    "    # Total vertical extent of diagram\n",
    "    xMax = topEdge / aspect\n",
    "    draw_vertical_bars(\n",
    "        ax,\n",
    "        colorDict,  # type: ignore\n",
    "        fontsize,\n",
    "        leftLabels,\n",
    "        leftWidths,\n",
    "        rightLabels,\n",
    "        rightWidths,\n",
    "        xMax,  # type: ignore\n",
    "    )\n",
    "    plot_strips(\n",
    "        ax,\n",
    "        colorDict,  # type: ignore\n",
    "        data_frame,\n",
    "        leftLabels,\n",
    "        leftWidths,\n",
    "        ns_l,\n",
    "        ns_r,\n",
    "        rightColor,\n",
    "        rightLabels,\n",
    "        rightWidths,\n",
    "        xMax,\n",
    "    )\n",
    "    if figSize is not None:\n",
    "        plt.gcf().set_size_inches(figSize)\n",
    "    save_image(figureName)\n",
    "    if closePlot:\n",
    "        plt.close()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def save_image(figureName: Optional[str]) -> None:\n",
    "    if figureName is not None:\n",
    "        file_name = f\"{figureName}.png\"\n",
    "        plt.savefig(file_name, bbox_inches=\"tight\", dpi=150)\n",
    "        LOGGER.info(\"Sankey diagram generated in '%s'\", file_name)\n",
    "\n",
    "\n",
    "def identify_labels(\n",
    "    dataFrame: DataFrame, leftLabels: List[str], rightLabels: List[str]\n",
    ") -> Tuple[ndarray, ndarray]:\n",
    "    # Identify left labels\n",
    "    if len(leftLabels) == 0:\n",
    "        leftLabels = pd.Series(dataFrame.left.unique()).unique()\n",
    "    else:\n",
    "        check_data_matches_labels(leftLabels, dataFrame[\"left\"], \"left\")\n",
    "    # Identify right labels\n",
    "    if len(rightLabels) == 0:\n",
    "        rightLabels = pd.Series(dataFrame.right.unique()).unique()\n",
    "    else:\n",
    "        check_data_matches_labels(rightLabels, dataFrame[\"right\"], \"right\")\n",
    "    return leftLabels, rightLabels\n",
    "\n",
    "\n",
    "def init_values(\n",
    "    ax: Optional[Any],\n",
    "    closePlot: bool,\n",
    "    figSize: Optional[Tuple[int, int]],\n",
    "    figureName: Optional[str],\n",
    "    left: Union[List, ndarray, Series],\n",
    "    leftLabels: Optional[List[str]],\n",
    "    leftWeight: Optional[ndarray],\n",
    "    rightLabels: Optional[List[str]],\n",
    "    rightWeight: Optional[ndarray],\n",
    ") -> Tuple[Any, List[str], ndarray, List[str], ndarray]:\n",
    "    deprecation_warnings(closePlot, figSize, figureName)\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if leftWeight is None:\n",
    "        leftWeight = []\n",
    "    if rightWeight is None:\n",
    "        rightWeight = []\n",
    "    if leftLabels is None:\n",
    "        leftLabels = []\n",
    "    if rightLabels is None:\n",
    "        rightLabels = []\n",
    "    # Check weights\n",
    "    if len(leftWeight) == 0:\n",
    "        leftWeight = np.ones(len(left))\n",
    "    if len(rightWeight) == 0:\n",
    "        rightWeight = leftWeight\n",
    "    return ax, leftLabels, leftWeight, rightLabels, rightWeight\n",
    "\n",
    "\n",
    "def deprecation_warnings(\n",
    "    closePlot: bool, figSize: Optional[Tuple[int, int]], figureName: Optional[str]\n",
    ") -> None:\n",
    "    warn = []\n",
    "    if figureName is not None:\n",
    "        msg = \"use of figureName in sankey() is deprecated\"\n",
    "        warnings.warn(msg, DeprecationWarning)\n",
    "        warn.append(msg[7:-14])\n",
    "    if closePlot is not False:\n",
    "        msg = \"use of closePlot in sankey() is deprecated\"\n",
    "        warnings.warn(msg, DeprecationWarning)\n",
    "        warn.append(msg[7:-14])\n",
    "    if figSize is not None:\n",
    "        msg = \"use of figSize in sankey() is deprecated\"\n",
    "        warnings.warn(msg, DeprecationWarning)\n",
    "        warn.append(msg[7:-14])\n",
    "    if warn:\n",
    "        LOGGER.warning(\n",
    "            \" The following arguments are deprecated and should be removed: %s\",\n",
    "            \", \".join(warn),\n",
    "        )\n",
    "\n",
    "\n",
    "def determine_widths(\n",
    "    dataFrame: DataFrame, leftLabels: ndarray, rightLabels: ndarray\n",
    ") -> Tuple[Dict, Dict]:\n",
    "    # Determine widths of individual strips\n",
    "    ns_l: Dict = defaultdict()\n",
    "    ns_r: Dict = defaultdict()\n",
    "    for leftLabel in leftLabels:\n",
    "        left_dict = {}\n",
    "        right_dict = {}\n",
    "        for rightLabel in rightLabels:\n",
    "            left_dict[rightLabel] = dataFrame[\n",
    "                (dataFrame.left == leftLabel) & (dataFrame.right == rightLabel)\n",
    "            ].leftWeight.sum()\n",
    "            right_dict[rightLabel] = dataFrame[\n",
    "                (dataFrame.left == leftLabel) & (dataFrame.right == rightLabel)\n",
    "            ].rightWeight.sum()\n",
    "        ns_l[leftLabel] = left_dict\n",
    "        ns_r[leftLabel] = right_dict\n",
    "    return ns_l, ns_r\n",
    "\n",
    "\n",
    "def draw_vertical_bars(\n",
    "    ax: Any,\n",
    "    colorDict: Union[Dict[str, Tuple[float, float, float]], Dict[str, str]],\n",
    "    fontsize: int,\n",
    "    leftLabels: ndarray,\n",
    "    leftWidths: Dict,\n",
    "    rightLabels: ndarray,\n",
    "    rightWidths: Dict,\n",
    "    xMax: float64,\n",
    ") -> None:\n",
    "    # Draw vertical bars on left and right of each  label's section & print label\n",
    "    for leftLabel in leftLabels:\n",
    "        ax.fill_between(\n",
    "            [-0.02 * xMax, 0],\n",
    "            2 * [leftWidths[leftLabel][\"bottom\"]],\n",
    "            2 * [leftWidths[leftLabel][\"bottom\"] + leftWidths[leftLabel][\"left\"]],\n",
    "            color=colorDict[leftLabel],\n",
    "            alpha=0.99,\n",
    "        )\n",
    "        ax.text(\n",
    "            -0.05 * xMax,\n",
    "            leftWidths[leftLabel][\"bottom\"] + 0.5 * leftWidths[leftLabel][\"left\"],\n",
    "            leftLabel,\n",
    "            {\"ha\": \"right\", \"va\": \"center\"},\n",
    "            fontsize=fontsize,\n",
    "        )\n",
    "    for rightLabel in rightLabels:\n",
    "        ax.fill_between(\n",
    "            [xMax, 1.02 * xMax],\n",
    "            2 * [rightWidths[rightLabel][\"bottom\"]],\n",
    "            2 * [rightWidths[rightLabel][\"bottom\"] + rightWidths[rightLabel][\"right\"]],\n",
    "            color=colorDict[rightLabel],\n",
    "            alpha=0.99,\n",
    "        )\n",
    "        ax.text(\n",
    "            1.05 * xMax,\n",
    "            rightWidths[rightLabel][\"bottom\"] + 0.5 * rightWidths[rightLabel][\"right\"],\n",
    "            rightLabel,\n",
    "            {\"ha\": \"left\", \"va\": \"center\"},\n",
    "            fontsize=fontsize,\n",
    "        )\n",
    "\n",
    "\n",
    "def create_colors(\n",
    "    allLabels: ndarray, colorDict: Optional[Dict[str, str]]\n",
    ") -> Union[Dict[str, Tuple[float, float, float]], Dict[str, str]]:\n",
    "    # If no colorDict given, make one\n",
    "    if colorDict is None:\n",
    "        colorDict = {}\n",
    "        palette = \"hls\"\n",
    "        colorPalette = sns.color_palette(palette, len(allLabels))\n",
    "        for i, label in enumerate(allLabels):\n",
    "            colorDict[label] = colorPalette[i]\n",
    "    else:\n",
    "        missing = [label for label in allLabels if label not in colorDict.keys()]\n",
    "        if missing:\n",
    "            raise ValueError(\n",
    "                \"The colorDict parameter is missing values for the following labels : \"\n",
    "                + \", \".join(missing)\n",
    "            )\n",
    "    LOGGER.debug(\"The colordict value are : %s\", colorDict)\n",
    "    return colorDict\n",
    "\n",
    "\n",
    "def _create_dataframe(\n",
    "    left: Union[List, ndarray, Series],\n",
    "    leftWeight: Union[ndarray, Series],\n",
    "    right: Union[ndarray, Series],\n",
    "    rightWeight: Union[ndarray, Series],\n",
    ") -> DataFrame:\n",
    "    # Create Dataframe\n",
    "    if isinstance(left, pd.Series):\n",
    "        left = left.reset_index(drop=True)\n",
    "    if isinstance(right, pd.Series):\n",
    "        right = right.reset_index(drop=True)\n",
    "    if isinstance(leftWeight, pd.Series):\n",
    "        leftWeight = leftWeight.reset_index(drop=True)\n",
    "    if isinstance(rightWeight, pd.Series):\n",
    "        rightWeight = rightWeight.reset_index(drop=True)\n",
    "    data_frame = pd.DataFrame(\n",
    "        {\n",
    "            \"left\": left,\n",
    "            \"right\": right,\n",
    "            \"leftWeight\": leftWeight,\n",
    "            \"rightWeight\": rightWeight,\n",
    "        },\n",
    "        index=range(len(left)),\n",
    "    )\n",
    "    if len(data_frame[(data_frame.left.isnull()) | (data_frame.right.isnull())]):\n",
    "        raise NullsInFrame(\"Sankey graph does not support null values.\")\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def plot_strips(\n",
    "    ax: Any,\n",
    "    colorDict: Union[Dict[str, Tuple[float, float, float]], Dict[str, str]],\n",
    "    dataFrame: DataFrame,\n",
    "    leftLabels: ndarray,\n",
    "    leftWidths: Dict,\n",
    "    ns_l: Dict,\n",
    "    ns_r: Dict,\n",
    "    rightColor: bool,\n",
    "    rightLabels: ndarray,\n",
    "    rightWidths: Dict,\n",
    "    xMax: float64,\n",
    ") -> None:\n",
    "    # Plot strips\n",
    "    for leftLabel in leftLabels:\n",
    "        for rightLabel in rightLabels:\n",
    "            label_color = leftLabel\n",
    "            if rightColor:\n",
    "                label_color = rightLabel\n",
    "            if (\n",
    "                len(\n",
    "                    dataFrame[\n",
    "                        (dataFrame.left == leftLabel) & (dataFrame.right == rightLabel)\n",
    "                    ]\n",
    "                )\n",
    "                > 0\n",
    "            ):\n",
    "                # Create array of y values for each strip, half at left value,\n",
    "                # half at right, convolve\n",
    "                ys_d = np.array(\n",
    "                    50 * [leftWidths[leftLabel][\"bottom\"]]\n",
    "                    + 50 * [rightWidths[rightLabel][\"bottom\"]]\n",
    "                )\n",
    "                ys_d = np.convolve(ys_d, 0.05 * np.ones(20), mode=\"valid\")\n",
    "                ys_d = np.convolve(ys_d, 0.05 * np.ones(20), mode=\"valid\")\n",
    "                ys_u = np.array(\n",
    "                    50 * [leftWidths[leftLabel][\"bottom\"] + ns_l[leftLabel][rightLabel]]\n",
    "                    + 50\n",
    "                    * [rightWidths[rightLabel][\"bottom\"] + ns_r[leftLabel][rightLabel]]\n",
    "                )\n",
    "                ys_u = np.convolve(ys_u, 0.05 * np.ones(20), mode=\"valid\")\n",
    "                ys_u = np.convolve(ys_u, 0.05 * np.ones(20), mode=\"valid\")\n",
    "\n",
    "                # Update bottom edges at each label so next strip starts at the\n",
    "                # right place\n",
    "                leftWidths[leftLabel][\"bottom\"] += ns_l[leftLabel][rightLabel]\n",
    "                rightWidths[rightLabel][\"bottom\"] += ns_r[leftLabel][rightLabel]\n",
    "                ax.fill_between(\n",
    "                    np.linspace(0, xMax, len(ys_d)),\n",
    "                    ys_d,\n",
    "                    ys_u,\n",
    "                    alpha=0.65,\n",
    "                    color=colorDict[label_color],\n",
    "                )\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def _get_positions_and_total_widths(\n",
    "    df: DataFrame, labels: ndarray, side: str\n",
    ") -> Tuple[Dict, float64]:\n",
    "    \"\"\"Determine positions of label patches and total widths\"\"\"\n",
    "    widths: Dict = defaultdict()\n",
    "    for i, label in enumerate(labels):\n",
    "        label_widths = {}\n",
    "        label_widths[side] = df[df[side] == label][side + \"Weight\"].sum()\n",
    "        print(\"a\")\n",
    "        if i == 0:\n",
    "            label_widths[\"bottom\"] = 0\n",
    "            label_widths[\"top\"] = label_widths[side]\n",
    "        else:\n",
    "            bottom_width = widths[labels[i - 1]][\"top\"]\n",
    "            weighted_sum = 0.05 * df[side + \"Weight\"].sum()\n",
    "            label_widths[\"bottom\"] = bottom_width + weighted_sum\n",
    "            label_widths[\"top\"] = label_widths[\"bottom\"] + label_widths[side]\n",
    "            topEdge = label_widths[\"top\"]\n",
    "        widths[label] = label_widths\n",
    "        LOGGER.debug(\"%s position of '%s' : %s\", side, label, label_widths)\n",
    "    return widths, topEdge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5b8c5b127d2cfe5bc3a1c933e197485eb9eba25154c3661362401503b4ef9d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
